import os
import pandas as pd
import chardet
# è®¾ç½®è¦éå†çš„æ–‡ä»¶å¤¹è·¯å¾„
folder_path = "./car-csv-data"  # æ ¹æ®ä½ çš„ç›®å½•ç»“æ„ä¿®æ”¹

def detect_encoding(file_path):
    """è‡ªåŠ¨æ£€æµ‹æ–‡ä»¶ç¼–ç """
    with open(file_path, 'rb') as file:
        raw_data = file.read()
        result = chardet.detect(raw_data)
        encoding = result['encoding']
        # å°è¯•ç”¨ chardet å¤±è´¥æ—¶å¤‡ç”¨ç¼–ç 
        try:
            with open(file_path, mode='r', encoding=encoding) as f:
                f.read(100)  # è¯»å–æ–‡ä»¶çš„ä¸€éƒ¨åˆ†æ¥ç¡®è®¤ç¼–ç æ˜¯å¦æ­£ç¡®
            return encoding
        except UnicodeDecodeError:
            print(f"ç¼–ç  {encoding} æ— æ³•æ­£ç¡®è§£ç ï¼Œå°è¯•ä½¿ç”¨ utf-8")
            return 'utf-8'
k = 0
# éå†è¯¥æ–‡ä»¶å¤¹ä¸‹æ‰€æœ‰ CSV æ–‡ä»¶
for filename in os.listdir(folder_path):
    if filename.endswith(".csv"):
        file_path = os.path.join(folder_path, filename)
        print(f"å¤„ç†æ–‡ä»¶: {file_path}")

        try:
            # è¯»å– CSV æ–‡ä»¶
            df = pd.read_csv(file_path, encoding=detect_encoding(file_path))  # å¦‚é‡ç¼–ç é—®é¢˜å¯æ¢æˆ 'gbk', 'utf-8-sig' ç­‰

            # è·å–å¹¶æ‰“å°åŸå§‹è¡¨å¤´
            original_columns = df.columns.tolist()
            print("åŸå§‹è¡¨å¤´:", original_columns)
            k+=1
            print(k)
            # === ğŸ”§ åœ¨è¿™é‡Œå†™ä½ çš„è¡¨å¤´é¢„å¤„ç†é€»è¾‘ ===
            # ä¾‹å¦‚ï¼šé‡å‘½åã€å»é™¤ç©ºæ ¼ã€ç»Ÿä¸€å¤§å°å†™ç­‰
            # df.columns = [col.strip().lower().replace(" ", "_") for col in df.columns]

            # === âœ… å¯é€‰ï¼šä¿å­˜å¤„ç†åçš„æ–‡ä»¶ï¼ˆæ¯”å¦‚å¦å­˜ä¸º _processed.csvï¼‰ ===
            # new_file_path = file_path.replace(".csv", "_processed.csv")
            # df.to_csv(new_file_path, index=False)

        except Exception as e:
            print(f"âš ï¸ å¤„ç†æ–‡ä»¶å‡ºé”™: {file_path}ï¼ŒåŸå› : {e}")
