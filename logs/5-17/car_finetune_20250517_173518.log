"D:\Program Files\conda\envs\KGcar\python.exe" D:/PythonWeb/Car_QuestionSystem/train.py
Sliding Window Attention is enabled but not implemented for `sdpa`; unexpected results may be encountered.
2025-05-17 17:35:18,791 - INFO - 加载数据中...
2025-05-17 17:35:18,801 - INFO - 加载完成，共 1449 条样本
Map: 100%|██████████| 1449/1449 [00:01<00:00, 1342.36 examples/s]
2025-05-17 17:35:19,962 - INFO - 数据编码完成，开始训练...
D:\PythonWeb\Car_QuestionSystem\train.py:112: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.
  trainer = Trainer(
No label_names provided for model class `PeftModelForCausalLM`. Since `PeftModel` hides base models input arguments, if label_names is not given, label_names can't be set automatically within `Trainer`. Note that empty label_names list will be used instead.
  2%|▏         | 10/543 [03:58<3:31:00, 23.75s/it]{'loss': 1.6558, 'grad_norm': 1.4716784954071045, 'learning_rate': 9e-06, 'epoch': 0.06}
  4%|▎         | 20/543 [07:56<3:27:46, 23.84s/it]{'loss': 1.6108, 'grad_norm': 1.0690209865570068, 'learning_rate': 1.9e-05, 'epoch': 0.11}
  6%|▌         | 30/543 [11:54<3:23:45, 23.83s/it]{'loss': 1.5258, 'grad_norm': 1.1044038534164429, 'learning_rate': 2.9e-05, 'epoch': 0.17}
  7%|▋         | 40/543 [15:53<3:19:59, 23.86s/it]{'loss': 1.3276, 'grad_norm': 1.2735190391540527, 'learning_rate': 3.9000000000000006e-05, 'epoch': 0.22}
  9%|▉         | 50/543 [19:51<3:16:00, 23.85s/it]{'loss': 1.1139, 'grad_norm': 1.125196933746338, 'learning_rate': 4.9e-05, 'epoch': 0.28}
 11%|█         | 60/543 [23:49<3:11:33, 23.80s/it]{'loss': 1.0188, 'grad_norm': 0.9508764743804932, 'learning_rate': 4.908722109533469e-05, 'epoch': 0.33}
 13%|█▎        | 70/543 [27:47<3:07:33, 23.79s/it]{'loss': 0.9155, 'grad_norm': 1.0806742906570435, 'learning_rate': 4.807302231237323e-05, 'epoch': 0.39}
 15%|█▍        | 80/543 [31:45<3:03:23, 23.77s/it]{'loss': 0.8753, 'grad_norm': 1.3391433954238892, 'learning_rate': 4.705882352941177e-05, 'epoch': 0.44}
 17%|█▋        | 90/543 [35:43<2:59:49, 23.82s/it]{'loss': 0.8197, 'grad_norm': 1.3420168161392212, 'learning_rate': 4.604462474645031e-05, 'epoch': 0.5}
 18%|█▊        | 100/543 [39:41<2:55:50, 23.82s/it]{'loss': 0.8395, 'grad_norm': 1.433414101600647, 'learning_rate': 4.503042596348885e-05, 'epoch': 0.55}
 20%|██        | 110/543 [43:40<2:52:03, 23.84s/it]{'loss': 0.7641, 'grad_norm': 1.3069154024124146, 'learning_rate': 4.401622718052739e-05, 'epoch': 0.61}
 22%|██▏       | 120/543 [47:38<2:47:53, 23.82s/it]{'loss': 0.7699, 'grad_norm': 1.2163923978805542, 'learning_rate': 4.300202839756592e-05, 'epoch': 0.66}
 24%|██▍       | 130/543 [51:36<2:44:14, 23.86s/it]{'loss': 0.6959, 'grad_norm': 1.9100086688995361, 'learning_rate': 4.198782961460446e-05, 'epoch': 0.72}
 26%|██▌       | 140/543 [55:34<2:39:18, 23.72s/it]{'loss': 0.6758, 'grad_norm': 1.415330171585083, 'learning_rate': 4.097363083164301e-05, 'epoch': 0.77}
 28%|██▊       | 150/543 [59:32<2:36:04, 23.83s/it]{'loss': 0.7182, 'grad_norm': 1.3147425651550293, 'learning_rate': 3.995943204868154e-05, 'epoch': 0.83}
 29%|██▉       | 160/543 [1:03:31<2:32:08, 23.83s/it]{'loss': 0.6921, 'grad_norm': 1.6193784475326538, 'learning_rate': 3.894523326572008e-05, 'epoch': 0.88}
 31%|███▏      | 170/543 [1:07:29<2:28:03, 23.82s/it]{'loss': 0.6764, 'grad_norm': 1.484674334526062, 'learning_rate': 3.793103448275862e-05, 'epoch': 0.94}
 33%|███▎      | 180/543 [1:11:27<2:24:19, 23.85s/it]{'loss': 0.6277, 'grad_norm': 1.7162953615188599, 'learning_rate': 3.691683569979716e-05, 'epoch': 0.99}
 35%|███▍      | 190/543 [1:15:04<2:17:17, 23.33s/it]{'loss': 0.6021, 'grad_norm': 1.5832632780075073, 'learning_rate': 3.59026369168357e-05, 'epoch': 1.04}
 37%|███▋      | 200/543 [1:19:01<2:15:44, 23.75s/it]{'loss': 0.6114, 'grad_norm': 1.5825268030166626, 'learning_rate': 3.488843813387424e-05, 'epoch': 1.1}
 39%|███▊      | 210/543 [1:23:00<2:12:21, 23.85s/it]{'loss': 0.6172, 'grad_norm': 2.000040292739868, 'learning_rate': 3.387423935091278e-05, 'epoch': 1.15}
 41%|████      | 220/543 [1:26:59<2:08:46, 23.92s/it]{'loss': 0.6063, 'grad_norm': 1.6705673933029175, 'learning_rate': 3.286004056795132e-05, 'epoch': 1.21}
 42%|████▏     | 230/543 [1:30:57<2:04:12, 23.81s/it]{'loss': 0.6085, 'grad_norm': 1.6184699535369873, 'learning_rate': 3.184584178498986e-05, 'epoch': 1.26}
 44%|████▍     | 240/543 [1:34:55<2:00:13, 23.81s/it]{'loss': 0.5764, 'grad_norm': 1.769629716873169, 'learning_rate': 3.0831643002028396e-05, 'epoch': 1.32}
 46%|████▌     | 250/543 [1:38:54<1:56:25, 23.84s/it]{'loss': 0.5686, 'grad_norm': 2.0124428272247314, 'learning_rate': 2.9817444219066936e-05, 'epoch': 1.38}
 48%|████▊     | 260/543 [1:42:51<1:52:24, 23.83s/it]{'loss': 0.5706, 'grad_norm': 2.032061815261841, 'learning_rate': 2.880324543610548e-05, 'epoch': 1.43}
 50%|████▉     | 270/543 [1:46:49<1:47:49, 23.70s/it]{'loss': 0.5545, 'grad_norm': 1.8663537502288818, 'learning_rate': 2.778904665314402e-05, 'epoch': 1.49}
 52%|█████▏    | 280/543 [1:50:47<1:44:19, 23.80s/it]{'loss': 0.5441, 'grad_norm': 1.7668108940124512, 'learning_rate': 2.6774847870182556e-05, 'epoch': 1.54}
 53%|█████▎    | 290/543 [1:54:44<1:39:59, 23.71s/it]{'loss': 0.5651, 'grad_norm': 2.3725831508636475, 'learning_rate': 2.5760649087221096e-05, 'epoch': 1.6}
 55%|█████▌    | 300/543 [1:58:41<1:35:58, 23.70s/it]{'loss': 0.5496, 'grad_norm': 2.2850635051727295, 'learning_rate': 2.4746450304259636e-05, 'epoch': 1.65}
 57%|█████▋    | 310/543 [2:02:39<1:32:25, 23.80s/it]{'loss': 0.5304, 'grad_norm': 2.1003730297088623, 'learning_rate': 2.3732251521298176e-05, 'epoch': 1.71}
 59%|█████▉    | 320/543 [2:06:37<1:28:32, 23.82s/it]{'loss': 0.5198, 'grad_norm': 1.7977432012557983, 'learning_rate': 2.2718052738336716e-05, 'epoch': 1.76}
 61%|██████    | 330/543 [2:10:35<1:24:37, 23.84s/it]{'loss': 0.5842, 'grad_norm': 2.157912492752075, 'learning_rate': 2.1703853955375257e-05, 'epoch': 1.82}
 63%|██████▎   | 340/543 [2:14:33<1:20:42, 23.86s/it]{'loss': 0.5694, 'grad_norm': 1.8295615911483765, 'learning_rate': 2.0689655172413793e-05, 'epoch': 1.87}
 64%|██████▍   | 350/543 [2:18:31<1:16:21, 23.74s/it]{'loss': 0.5384, 'grad_norm': 1.910651683807373, 'learning_rate': 1.9675456389452333e-05, 'epoch': 1.93}
 66%|██████▋   | 360/543 [2:22:29<1:12:41, 23.83s/it]{'loss': 0.5045, 'grad_norm': 1.9694592952728271, 'learning_rate': 1.8661257606490873e-05, 'epoch': 1.98}
 68%|██████▊   | 370/543 [2:26:05<1:06:16, 22.98s/it]{'loss': 0.5551, 'grad_norm': 1.9177632331848145, 'learning_rate': 1.7647058823529414e-05, 'epoch': 2.03}
 70%|██████▉   | 380/543 [2:30:03<1:04:38, 23.79s/it]{'loss': 0.5259, 'grad_norm': 1.6142826080322266, 'learning_rate': 1.663286004056795e-05, 'epoch': 2.09}
 72%|███████▏  | 390/543 [2:34:01<1:00:41, 23.80s/it]{'loss': 0.5267, 'grad_norm': 1.9835774898529053, 'learning_rate': 1.5618661257606494e-05, 'epoch': 2.14}
 74%|███████▎  | 400/543 [2:37:58<56:29, 23.70s/it]{'loss': 0.494, 'grad_norm': 1.870053768157959, 'learning_rate': 1.460446247464503e-05, 'epoch': 2.2}
 76%|███████▌  | 410/543 [2:41:56<52:47, 23.81s/it]{'loss': 0.5203, 'grad_norm': 1.8021266460418701, 'learning_rate': 1.3590263691683572e-05, 'epoch': 2.25}
 77%|███████▋  | 420/543 [2:45:54<48:36, 23.71s/it]{'loss': 0.4887, 'grad_norm': 1.8358380794525146, 'learning_rate': 1.257606490872211e-05, 'epoch': 2.31}
 79%|███████▉  | 430/543 [2:49:51<44:38, 23.70s/it]{'loss': 0.4949, 'grad_norm': 2.0548715591430664, 'learning_rate': 1.156186612576065e-05, 'epoch': 2.36}
 81%|████████  | 440/543 [2:53:49<40:51, 23.80s/it]{'loss': 0.4689, 'grad_norm': 2.085583448410034, 'learning_rate': 1.054766734279919e-05, 'epoch': 2.42}
 83%|████████▎ | 450/543 [2:57:47<36:54, 23.82s/it]{'loss': 0.4741, 'grad_norm': 1.7044732570648193, 'learning_rate': 9.533468559837728e-06, 'epoch': 2.47}
 85%|████████▍ | 460/543 [3:01:44<32:49, 23.73s/it]{'loss': 0.4688, 'grad_norm': 2.272174119949341, 'learning_rate': 8.519269776876268e-06, 'epoch': 2.53}
 87%|████████▋ | 470/543 [3:05:43<28:58, 23.82s/it]{'loss': 0.4911, 'grad_norm': 1.9372739791870117, 'learning_rate': 7.505070993914808e-06, 'epoch': 2.58}
 88%|████████▊ | 480/543 [3:10:07<29:36, 28.20s/it]{'loss': 0.5369, 'grad_norm': 1.8707177639007568, 'learning_rate': 6.490872210953347e-06, 'epoch': 2.64}
 90%|█████████ | 490/543 [3:16:59<39:08, 44.31s/it]{'loss': 0.5016, 'grad_norm': 2.0168583393096924, 'learning_rate': 5.4766734279918865e-06, 'epoch': 2.7}
 92%|█████████▏| 500/543 [3:23:22<26:22, 36.81s/it]{'loss': 0.4855, 'grad_norm': 2.085268259048462, 'learning_rate': 4.462474645030426e-06, 'epoch': 2.75}
 94%|█████████▍| 510/543 [3:30:45<29:30, 53.65s/it]{'loss': 0.4812, 'grad_norm': 2.0229604244232178, 'learning_rate': 3.448275862068966e-06, 'epoch': 2.81}
 96%|█████████▌| 520/543 [3:40:20<23:04, 60.22s/it]{'loss': 0.4773, 'grad_norm': 2.138198137283325, 'learning_rate': 2.434077079107505e-06, 'epoch': 2.86}
 98%|█████████▊| 530/543 [3:49:44<12:50, 59.28s/it]{'loss': 0.5209, 'grad_norm': 1.9993464946746826, 'learning_rate': 1.4198782961460448e-06, 'epoch': 2.92}
 99%|█████████▉| 540/543 [3:59:32<02:40, 53.56s/it]{'loss': 0.4817, 'grad_norm': 2.3030636310577393, 'learning_rate': 4.056795131845842e-07, 'epoch': 2.97}
100%|██████████| 543/543 [4:01:24<00:00, 26.67s/it]
{'train_runtime': 14484.1371, 'train_samples_per_second': 0.3, 'train_steps_per_second': 0.037, 'train_loss': 0.675809865498411, 'epoch': 2.99}
2025-05-17 21:36:44,447 - INFO - 训练完成，保存模型中...
2025-05-17 21:36:44,684 - INFO - 模型和分词器保存完成 ✅

